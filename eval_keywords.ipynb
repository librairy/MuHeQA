{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2996a0d8",
   "metadata": {},
   "source": [
    "# Experiment Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc611c5",
   "metadata": {},
   "source": [
    "## Install dependencies and prepare modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4d1454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (22.2.2)\n",
      "Requirement already satisfied: flair in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (0.11.1)\n",
      "Requirement already satisfied: janome in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (0.4.2)\n",
      "Requirement already satisfied: ftfy in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (6.1.1)\n",
      "Requirement already satisfied: mpld3==0.3 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (0.3)\n",
      "Requirement already satisfied: sentencepiece==0.1.95 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (0.1.95)\n",
      "Requirement already satisfied: gdown==3.12.2 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (3.12.2)\n",
      "Requirement already satisfied: tabulate in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (0.8.9)\n",
      "Requirement already satisfied: wikipedia-api in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (0.5.4)\n",
      "Requirement already satisfied: bpemb>=0.3.2 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (0.3.3)\n",
      "Requirement already satisfied: regex in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (2022.1.18)\n",
      "Requirement already satisfied: conllu>=4.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (4.4.1)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (2.0.0)\n",
      "Requirement already satisfied: pptree in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (3.1)\n",
      "Requirement already satisfied: segtok>=1.5.7 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (1.5.11)\n",
      "Requirement already satisfied: huggingface-hub in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (0.4.0)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (4.1.2)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (1.2.13)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (1.10.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (2.8.2)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (3.5.0)\n",
      "Requirement already satisfied: transformers>=4.0.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (4.16.1)\n",
      "Requirement already satisfied: hyperopt>=0.2.7 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (0.2.7)\n",
      "Requirement already satisfied: lxml in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (4.8.0)\n",
      "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (4.6.5)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (4.62.3)\n",
      "Requirement already satisfied: langdetect in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (1.0.9)\n",
      "Requirement already satisfied: more-itertools~=8.8.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (8.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from flair) (1.0.1)\n",
      "Requirement already satisfied: six in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from gdown==3.12.2->flair) (1.16.0)\n",
      "Requirement already satisfied: requests[socks] in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from gdown==3.12.2->flair) (2.26.0)\n",
      "Requirement already satisfied: filelock in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from gdown==3.12.2->flair) (3.4.2)\n",
      "Requirement already satisfied: numpy in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from bpemb>=0.3.2->flair) (1.22.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from deprecated>=1.2.4->flair) (1.14.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from gensim>=3.4.0->flair) (1.7.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from gensim>=3.4.0->flair) (5.2.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from hyperopt>=0.2.7->flair) (2.0.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from hyperopt>=0.2.7->flair) (2.8)\n",
      "Requirement already satisfied: future in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from hyperopt>=0.2.7->flair) (0.18.2)\n",
      "Requirement already satisfied: py4j in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from hyperopt>=0.2.7->flair) (0.10.9.5)\n",
      "Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from konoha<5.0.0,>=4.0.0->flair) (3.10.1)\n",
      "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (4.28.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from scikit-learn>=0.21.3->flair) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from torch!=1.8,>=1.5.0->flair) (4.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from transformers>=4.0.0->flair) (6.0)\n",
      "Requirement already satisfied: sacremoses in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from transformers>=4.0.0->flair) (0.0.47)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from transformers>=4.0.0->flair) (0.11.4)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown==3.12.2->flair) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown==3.12.2->flair) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown==3.12.2->flair) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown==3.12.2->flair) (2021.10.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from requests[socks]->gdown==3.12.2->flair) (1.7.1)\n",
      "Requirement already satisfied: click in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: coloredlogs in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from coloredlogs) (10.0)\n",
      "Requirement already satisfied: unidecode in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: fcache in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (0.4.7)\n",
      "Requirement already satisfied: appdirs in /Users/cbadenes/miniforge3/lib/python3.9/site-packages (from fcache) (1.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2022-08-29 17:04:12,745 - muheqa - DEBUG - initializing Entity class instance... (entity.py:11)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:04:18,780 - muheqa - DEBUG - initializing Concept class instance... (concept.py:12)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:04:19,462 - muheqa - DEBUG - initializing Keyword class instance... (keyword.py:11)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:04:19,463 - muheqa - DEBUG - initializing Entity class instance... (entity.py:11)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:04:25,125 - muheqa - DEBUG - initializing Concept class instance... (concept.py:12)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install flair\n",
    "!pip install coloredlogs\n",
    "!pip install unidecode\n",
    "!pip install fcache\n",
    "\n",
    "import coloredlogs, logging\n",
    "import application.logformatter as lf\n",
    "from fcache.cache import FileCache\n",
    "\n",
    "log_level = logging.DEBUG\n",
    "\n",
    "fh = logging.StreamHandler()\n",
    "fh.setFormatter(lf.CustomFormatter())\n",
    "fh.setLevel(log_level)\n",
    "\n",
    "logger = logging.getLogger('muheqa')\n",
    "logger.addHandler(fh)\n",
    "logger.setLevel(log_level)\n",
    "\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "import application.summary.entity as ent\n",
    "import application.summary.concept as cp\n",
    "import application.summary.keyword as key\n",
    "import application.cache as cache\n",
    "\n",
    "entity_discovery  = ent.Entity()\n",
    "concept_discovery = cp.Concept()\n",
    "keyword_discovery = key.Keyword()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e8843",
   "metadata": {},
   "source": [
    "## Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fbe1d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics are ready\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "\n",
    "def normalize(label):\n",
    "  return unidecode.unidecode(label.strip()).lower().replace(\" \",\"_\")\n",
    "\n",
    "def precision(tp,fp):\n",
    "  if (fp+tp == 0):\n",
    "    return 0.0\n",
    "  return tp / (fp + tp)\n",
    "\n",
    "def recall(tp,fn):\n",
    "  if (fn+tp == 0):\n",
    "    return 0.0\n",
    "  return tp / (fn + tp)\n",
    "\n",
    "def f1(tp,fp,fn):\n",
    "  p = precision(tp,fp)\n",
    "  r = recall(tp,fn)\n",
    "  if (p+r == 0):\n",
    "    return 0.0\n",
    "  return 2 * ((p*r)/(p+r))\n",
    "\n",
    "def average(values):\n",
    "  return sum(values) / len(values) \n",
    "\n",
    "# lists of entity lists\n",
    "def evaluate_labels(true_list,pred_list):\n",
    "  tp, tn, fp, fn = 0, 0, 0, 0\n",
    "  precision_list, recall_list, f1_list = [], [], []\n",
    "  empty_values = 0\n",
    "  for index in range(len(true_list)):\n",
    "    # normalize entities\n",
    "    valid_entities = [normalize(e) for e in true_list[index] if e != '']\n",
    "    predicted_entities = [normalize(e) for e in pred_list[index]]\n",
    "    ptp, ptn, pfp, pfn = 0, 0, 0, 0\n",
    "    if (len(valid_entities)==0):\n",
    "      empty_values += 1\n",
    "    for entity in valid_entities:\n",
    "      if (entity not in predicted_entities):\n",
    "        pfn += 1\n",
    "    for entity in predicted_entities:\n",
    "      if (entity in valid_entities):\n",
    "        ptp += 1\n",
    "      else:\n",
    "        pfp += 1    \n",
    "    precision_list.append(precision(ptp,pfp))\n",
    "    recall_list.append(recall(ptp,pfn))\n",
    "    f1_list.append(f1(ptp,pfp,pfn))\n",
    "    tp += ptp\n",
    "    tn += ptn\n",
    "    fp += pfp\n",
    "    fn += pfn  \n",
    "  return  {\n",
    "      'total': index,\n",
    "      'empty': empty_values,\n",
    "      'tp': tp,\n",
    "      'tn': tn, \n",
    "      'fp': fp,\n",
    "      'fn':fn,\n",
    "      'micro-precision': precision(tp,fp),\n",
    "      'micro-recall': recall(tp,fn),\n",
    "      'micro-f1': f1(tp,fp,fn),\n",
    "      'macro-precision': average(precision_list),\n",
    "      'macro-recall': average(recall_list),\n",
    "      'macro-f1': average(f1_list)\n",
    "  }\n",
    "\n",
    "print(\"metrics are ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a283235",
   "metadata": {},
   "source": [
    "## Load SOTA Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0adc0",
   "metadata": {},
   "source": [
    "### FLERT\n",
    "\n",
    "From paper: Schweter, Stefan and A. Akbik. “FLERT: Document-Level Features for Named Entity Recognition.” ArXiv abs/2011.06993 (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d02ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2022-08-29 17:04:46,702 - muheqa - DEBUG - initializing muheqa_flert cache ... (cache.py:9)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 110 elements from cache: /Users/cbadenes/Library/Caches/muheqa_flert/cache ...\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "flert_tagger = SequenceTagger.load(\"flair/ner-english-large\")\n",
    "flert_cache = cache.Cache(\"muheqa_flert\")\n",
    "\n",
    "def get_entities_by_flert(text):\n",
    "    if (flert_cache.exists(text)):\n",
    "        return flert_cache.get(text)\n",
    "    sentence = Sentence(text)\n",
    "    flert_tagger.predict(sentence)\n",
    "    entities = []\n",
    "    for entity in sentence.get_spans('ner'):\n",
    "        entities.append(entity.text)\n",
    "    flert_cache.set(text,entities)\n",
    "    return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23442254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2022-08-29 17:04:46,710 - muheqa - DEBUG - reading value of 7bd3189e6a6c8993bc12244a66e09c65 from cache (cache.py:29)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['George Washington', 'Washington']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities_by_flert(\"George Washington went to Washington\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60fa521",
   "metadata": {},
   "source": [
    "### BERT-based NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdc8890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2022-08-29 17:04:52,448 - muheqa - DEBUG - initializing muheqa_bert cache ... (cache.py:9)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 110 elements from cache: /Users/cbadenes/Library/Caches/muheqa_bert/cache ...\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "bert_model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "bert_cache = cache.Cache(\"muheqa_bert\")\n",
    "\n",
    "\n",
    "bert_nlp = pipeline(\"ner\", model=bert_model, tokenizer=bert_tokenizer)\n",
    "\n",
    "def get_entities_by_bert_base(text):\n",
    "    if (bert_cache.exists(text)):\n",
    "        return bert_cache.get(text)\n",
    "    entities = []\n",
    "    entity = \"\"\n",
    "    index = -1\n",
    "    offset = -1\n",
    "    for token in bert_nlp(text):\n",
    "        if (index == -1):\n",
    "            index = token['index']\n",
    "            offset = token['start']\n",
    "        word = token['word']\n",
    "        if (word[0] == '#'):\n",
    "            word = token['word'].replace(\"#\",\"\")        \n",
    "        if (token['start']== offset):\n",
    "            entity += word\n",
    "        elif (token['index']-index < 2):\n",
    "            entity += \" \" + word\n",
    "        else:\n",
    "            entities.append(entity)\n",
    "            entity = word\n",
    "        index = token['index']\n",
    "        offset = token['end']\n",
    "    if (len(entity) > 0):    \n",
    "        entities.append(entity)\n",
    "    bert_cache.set(text,entities)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67f15068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2022-08-29 17:04:52,454 - muheqa - DEBUG - reading value of 7bd3189e6a6c8993bc12244a66e09c65 from cache (cache.py:29)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['George Washington', 'Washington']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit test\n",
    "get_entities_by_bert_base(\"George Washington went to Washington\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd40da21",
   "metadata": {},
   "source": [
    "### RoBERTA-based NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9efce6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2022-08-29 17:05:00,790 - muheqa - DEBUG - initializing muheqa_roberta cache ... (cache.py:9)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 110 elements from cache: /Users/cbadenes/Library/Caches/muheqa_roberta/cache ...\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/roberta-large-ner-english\")\n",
    "roberta_model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/roberta-large-ner-english\")\n",
    "roberta_cache = cache.Cache(\"muheqa_roberta\")\n",
    "\n",
    "roberta_nlp = pipeline(\"ner\", model=roberta_model, tokenizer=roberta_tokenizer)\n",
    "\n",
    "def get_entities_by_roberta_base(text):\n",
    "    if (roberta_cache.exists(text)):\n",
    "        return roberta_cache.get(text)\n",
    "    entities = []\n",
    "    entity = \"\"\n",
    "    index = -1\n",
    "    offset = -1\n",
    "    for token in roberta_nlp(text):\n",
    "        if (index == -1):\n",
    "            index = token['index']\n",
    "            offset = token['start']\n",
    "        word = token['word']\n",
    "        if (word[0] == '#'):\n",
    "            word = token['word'].replace(\"#\",\"\")        \n",
    "        if (token['start']== offset):\n",
    "            entity += word\n",
    "        elif (token['index']-index < 2):\n",
    "            entity += \" \" + word\n",
    "        else:\n",
    "            entities.append(entity.replace(\"Ġ\",\"\"))\n",
    "            entity = word\n",
    "        index = token['index']\n",
    "        offset = token['end']\n",
    "    if (len(entity) > 0):    \n",
    "        entities.append(entity.replace(\"Ġ\",\"\"))\n",
    "    roberta_cache.set(text,entities)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31409fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m2022-08-29 17:05:00,797 - muheqa - DEBUG - reading value of 7bd3189e6a6c8993bc12244a66e09c65 from cache (cache.py:29)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['George Washington', 'Washington']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit test\n",
    "get_entities_by_roberta_base(\"George Washington went to Washington\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d83bc43",
   "metadata": {},
   "source": [
    "# Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46808452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation methods are ready\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def json_file(name):\n",
    "  return name+\"-keywords.json\"\n",
    "\n",
    "def csv_file(name):\n",
    "  return name+\"-keywords.csv\"\n",
    "\n",
    "def evaluate_data(name,dataframe):\n",
    "    logging.getLogger('muheqa').setLevel(logging.WARNING)\n",
    "    l1, l2, l3, l4 = [], [], [], []\n",
    "    total = 0\n",
    "    for index, row in dataframe.iterrows():\n",
    "        question = row['question']\n",
    "        print(index,\":\",question)\n",
    "        l1.append(keyword_discovery.get(question))\n",
    "        l2.append(get_entities_by_flert(question))\n",
    "        l3.append(get_entities_by_bert_base(question))\n",
    "        l4.append(get_entities_by_roberta_base(question))\n",
    "        total += 1\n",
    "    dataframe['MuHeQA_Keywords']=l1\n",
    "    dataframe['FLERT_NER']=l2\n",
    "    dataframe['BERT_NER']=l3\n",
    "    dataframe['RoBERTA_NER']=l4\n",
    "    clear_output(wait=True)\n",
    "    print(total,\"questions analyzed!\")\n",
    "    dataframe.to_json(json_file(name), orient='split')\n",
    "    dataframe.to_csv(csv_file(name))\n",
    "    logging.getLogger('muheqa').setLevel(logging.DEBUG)\n",
    "    return dataframe\n",
    "\n",
    "def make_report(name,additional=[]):\n",
    "  \n",
    "  df = pd.read_json(json_file(name), orient='split')\n",
    "  y_true =df['entities'].tolist()\n",
    "  results = []\n",
    "  for col in df.columns:\n",
    "    if (col == 'question') or (col == 'entities'):\n",
    "      continue\n",
    "    y_pred = df[col].tolist()\n",
    "    result = evaluate_labels(y_true,y_pred)\n",
    "    result['model']=col\n",
    "    results.append(result)\n",
    "\n",
    "  for row in additional:\n",
    "    results.append(row)\n",
    "\n",
    "  df_results = pd.DataFrame(results)\n",
    "  return df_results\n",
    "\n",
    "print(\"evaluation methods are ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4ffe62",
   "metadata": {},
   "source": [
    "# Basic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aea0617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33;94m2022-08-29 17:05:00,808 - muheqa - INFO - Query: 'in which country was overnight delivery filmed in?' (2087347042.py:3)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:00,809 - muheqa - DEBUG - getting entities... (entity.py:19)\u001b[0m\n",
      "\u001b[33;94m2022-08-29 17:05:00,985 - muheqa - INFO - Entities:[] (2087347042.py:4)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:00,986 - muheqa - DEBUG - getting concepts ... (concept.py:18)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,261 - muheqa - DEBUG - Token:in [ IN]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,262 - muheqa - DEBUG - Token:which [ WDT]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,262 - muheqa - DEBUG - Token:country [ NN]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,262 - muheqa - DEBUG - Token:was [ VBD]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,262 - muheqa - DEBUG - Token:overnight [ JJ]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,262 - muheqa - DEBUG - Token:delivery [ NN]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,263 - muheqa - DEBUG - Token:filmed [ VBN]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,263 - muheqa - DEBUG - Token:in [ RP]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,263 - muheqa - DEBUG - Token:? [ .]  (concept.py:37)\u001b[0m\n",
      "\u001b[33;94m2022-08-29 17:05:01,263 - muheqa - INFO - Concepts:['country', 'overnight delivery'] (2087347042.py:5)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,263 - muheqa - DEBUG - getting entities... (entity.py:19)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,360 - muheqa - DEBUG - getting concepts ... (concept.py:18)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,620 - muheqa - DEBUG - Token:in [ IN]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,620 - muheqa - DEBUG - Token:which [ WDT]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,620 - muheqa - DEBUG - Token:country [ NN]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,620 - muheqa - DEBUG - Token:was [ VBD]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,621 - muheqa - DEBUG - Token:overnight [ JJ]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,621 - muheqa - DEBUG - Token:delivery [ NN]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,621 - muheqa - DEBUG - Token:filmed [ VBN]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,621 - muheqa - DEBUG - Token:in [ RP]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,621 - muheqa - DEBUG - Token:? [ .]  (concept.py:37)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,621 - muheqa - DEBUG - getting keywords from the entities:[] and the concepts:['country', 'overnight delivery'] (keyword.py:22)\u001b[0m\n",
      "\u001b[38;20m2022-08-29 17:05:01,622 - muheqa - DEBUG - no entities found (keyword.py:24)\u001b[0m\n",
      "\u001b[33;94m2022-08-29 17:05:01,622 - muheqa - INFO - Keywords:['country', 'overnight delivery'] (2087347042.py:6)\u001b[0m\n",
      "\u001b[33;94m2022-08-29 17:05:01,754 - muheqa - INFO - FLERT:[] (2087347042.py:7)\u001b[0m\n",
      "\u001b[33;94m2022-08-29 17:05:01,838 - muheqa - INFO - BERT:[] (2087347042.py:8)\u001b[0m\n",
      "\u001b[33;94m2022-08-29 17:05:01,937 - muheqa - INFO - RoBERTA:[] (2087347042.py:9)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#query = \"what does 2674 pandarus orbit?\"\n",
    "query = \"in which country was overnight delivery filmed in?\"\n",
    "logger.info(\"Query: '\" + query + \"'\")\n",
    "logger.info(\"Entities:\"+ str(entity_discovery.get(query)))\n",
    "logger.info(\"Concepts:\"+ str(concept_discovery.get(query)))\n",
    "logger.info(\"Keywords:\"+ str(keyword_discovery.get(query)))\n",
    "logger.info(\"FLERT:\"+ str(get_entities_by_flert(query)))\n",
    "logger.info(\"BERT:\"+ str(get_entities_by_bert_base(query)))\n",
    "logger.info(\"RoBERTA:\"+ str(get_entities_by_roberta_base(query)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79001455",
   "metadata": {},
   "source": [
    "# SimpleQuestions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01beb909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where did roger marquis die</td>\n",
       "      <td>[Roger Marquis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what was the cause of death of yves klein</td>\n",
       "      <td>[Yves Klein]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how does engelbert zaschka identify</td>\n",
       "      <td>[Engelbert Zaschka]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what position does pee wee reese play in baseball</td>\n",
       "      <td>[Pee Wee Reese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which Swiss conductor's cause of death is myoc...</td>\n",
       "      <td>[myocardial infarction]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question                 entities\n",
       "0                        Where did roger marquis die          [Roger Marquis]\n",
       "1          what was the cause of death of yves klein             [Yves Klein]\n",
       "2               how does engelbert zaschka identify       [Engelbert Zaschka]\n",
       "3  what position does pee wee reese play in baseball          [Pee Wee Reese]\n",
       "4  Which Swiss conductor's cause of death is myoc...  [myocardial infarction]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/simple_questions/wsq-labels.csv', index_col=0)\n",
    "# inverse predicates contain no entity. In all other cases, the entity corresponds to the subject.\n",
    "entities = []\n",
    "questions = []\n",
    "for index, row in df.iterrows():\n",
    "    entity = row['subject_label']  \n",
    "    question = row['question']\n",
    "    if (entity.lower() in question.lower()):\n",
    "        entities.append([entity])\n",
    "        questions.append(question)\n",
    "sq_df = pd.DataFrame(list(zip(questions, entities)),columns =['question', 'entities'])\n",
    "sq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64493b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5187</td>\n",
       "      <td>5187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5172</td>\n",
       "      <td>4806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Name an actor.</td>\n",
       "      <td>[defender]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              question    entities\n",
       "count             5187        5187\n",
       "unique            5172        4806\n",
       "top     Name an actor.  [defender]\n",
       "freq                 6          21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab25df4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 questions analyzed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "      <th>MuHeQA_Keywords</th>\n",
       "      <th>FLERT_NER</th>\n",
       "      <th>BERT_NER</th>\n",
       "      <th>RoBERTA_NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where did roger marquis die</td>\n",
       "      <td>[Roger Marquis]</td>\n",
       "      <td>[roger marquis]</td>\n",
       "      <td>[roger marquis]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[roger marquis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what was the cause of death of yves klein</td>\n",
       "      <td>[Yves Klein]</td>\n",
       "      <td>[yves klein]</td>\n",
       "      <td>[yves klein]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[yves klein]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how does engelbert zaschka identify</td>\n",
       "      <td>[Engelbert Zaschka]</td>\n",
       "      <td>[engelbert zaschka]</td>\n",
       "      <td>[engelbert zaschka]</td>\n",
       "      <td>[engel, zasch]</td>\n",
       "      <td>[engelbert zaschka]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what position does pee wee reese play in baseball</td>\n",
       "      <td>[Pee Wee Reese]</td>\n",
       "      <td>[pee wee reese]</td>\n",
       "      <td>[pee wee reese]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[pee wee reese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which Swiss conductor's cause of death is myoc...</td>\n",
       "      <td>[myocardial infarction]</td>\n",
       "      <td>[swiss conductor]</td>\n",
       "      <td>[Swiss]</td>\n",
       "      <td>[Swiss]</td>\n",
       "      <td>[Swiss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>what language was the act of killing in?</td>\n",
       "      <td>[The Act of Killing]</td>\n",
       "      <td>[language]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>which type of film is the bitter tea of genera...</td>\n",
       "      <td>[The Bitter Tea of General Yen]</td>\n",
       "      <td>[general yen]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Who is an artist signed to warner bros. records</td>\n",
       "      <td>[Warner Bros. Records]</td>\n",
       "      <td>[warner bros. records]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[warner bros. records]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>who is a person with politician as a profession</td>\n",
       "      <td>[politician]</td>\n",
       "      <td>[profession]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Name a drama film.</td>\n",
       "      <td>[drama film]</td>\n",
       "      <td>[drama film]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0                         Where did roger marquis die   \n",
       "1           what was the cause of death of yves klein   \n",
       "2                how does engelbert zaschka identify    \n",
       "3   what position does pee wee reese play in baseball   \n",
       "4   Which Swiss conductor's cause of death is myoc...   \n",
       "..                                                ...   \n",
       "95           what language was the act of killing in?   \n",
       "96  which type of film is the bitter tea of genera...   \n",
       "97    Who is an artist signed to warner bros. records   \n",
       "98    who is a person with politician as a profession   \n",
       "99                                 Name a drama film.   \n",
       "\n",
       "                           entities         MuHeQA_Keywords  \\\n",
       "0                   [Roger Marquis]         [roger marquis]   \n",
       "1                      [Yves Klein]            [yves klein]   \n",
       "2               [Engelbert Zaschka]     [engelbert zaschka]   \n",
       "3                   [Pee Wee Reese]         [pee wee reese]   \n",
       "4           [myocardial infarction]       [swiss conductor]   \n",
       "..                              ...                     ...   \n",
       "95             [The Act of Killing]              [language]   \n",
       "96  [The Bitter Tea of General Yen]           [general yen]   \n",
       "97           [Warner Bros. Records]  [warner bros. records]   \n",
       "98                     [politician]            [profession]   \n",
       "99                     [drama film]            [drama film]   \n",
       "\n",
       "              FLERT_NER        BERT_NER             RoBERTA_NER  \n",
       "0       [roger marquis]              []         [roger marquis]  \n",
       "1          [yves klein]              []            [yves klein]  \n",
       "2   [engelbert zaschka]  [engel, zasch]     [engelbert zaschka]  \n",
       "3       [pee wee reese]              []         [pee wee reese]  \n",
       "4               [Swiss]         [Swiss]                 [Swiss]  \n",
       "..                  ...             ...                     ...  \n",
       "95                   []              []                      []  \n",
       "96                   []              []                      []  \n",
       "97                   []              []  [warner bros. records]  \n",
       "98                   []              []                      []  \n",
       "99                   []              []                      []  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_data('sq_results',sq_df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeffef58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>empty</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>micro-precision</th>\n",
       "      <th>micro-recall</th>\n",
       "      <th>micro-f1</th>\n",
       "      <th>macro-precision</th>\n",
       "      <th>macro-recall</th>\n",
       "      <th>macro-f1</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>0.690265</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>MuHeQA_Keywords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>FLERT_NER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>98</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>BERT_NER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>RoBERTA_NER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total  empty  tp  tn  fp  fn  micro-precision  micro-recall  micro-f1  \\\n",
       "0     99      0  78   0  35  22         0.690265          0.78  0.732394   \n",
       "1     99      0  55   0  10  45         0.846154          0.55  0.666667   \n",
       "2     99      0   2   0  17  98         0.105263          0.02  0.033613   \n",
       "3     99      0  64   0  22  36         0.744186          0.64  0.688172   \n",
       "\n",
       "   macro-precision  macro-recall  macro-f1            model  \n",
       "0            0.740          0.78  0.753333  MuHeQA_Keywords  \n",
       "1            0.540          0.55  0.543333        FLERT_NER  \n",
       "2            0.020          0.02  0.020000         BERT_NER  \n",
       "3            0.625          0.64  0.630000      RoBERTA_NER  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_report('sq_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d169906",
   "metadata": {},
   "source": [
    "## WikidataQA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "827157b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the president of Poland?</td>\n",
       "      <td>[president of Poland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many Turing awards have people from Austri...</td>\n",
       "      <td>[Turing awards,  Austria]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Give me all countries that have won a FIFA Wor...</td>\n",
       "      <td>[FIFA World Cup]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the population of Chile?</td>\n",
       "      <td>[Chile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is the author of One Piece?</td>\n",
       "      <td>[One Piece]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                    Who is the president of Poland?   \n",
       "1  How many Turing awards have people from Austri...   \n",
       "2  Give me all countries that have won a FIFA Wor...   \n",
       "3                   What is the population of Chile?   \n",
       "4                    Who is the author of One Piece?   \n",
       "\n",
       "                    entities  \n",
       "0      [president of Poland]  \n",
       "1  [Turing awards,  Austria]  \n",
       "2           [FIFA World Cup]  \n",
       "3                    [Chile]  \n",
       "4                [One Piece]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/wikidataQA/wqa-labels.csv', index_col=0)\n",
    "entities = []\n",
    "questions = []\n",
    "for index, row in df.iterrows():\n",
    "    entity = row['subject_labels'].replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\'\",\"\").split(\",\")\n",
    "    question = row['question']\n",
    "    if (entity[0].lower() in question.lower()):\n",
    "        entities.append(entity)\n",
    "        questions.append(question)\n",
    "wqa_df = pd.DataFrame(list(zip(questions, entities)),columns =['question', 'entities'])\n",
    "wqa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adda553d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>100</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Who is the president of Poland?</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               question entities\n",
       "count                               100      100\n",
       "unique                              100       94\n",
       "top     Who is the president of Poland?       []\n",
       "freq                                  1        4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wqa_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49459f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 questions analyzed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>entities</th>\n",
       "      <th>MuHeQA_Keywords</th>\n",
       "      <th>FLERT_NER</th>\n",
       "      <th>BERT_NER</th>\n",
       "      <th>RoBERTA_NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the president of Poland?</td>\n",
       "      <td>[president of Poland]</td>\n",
       "      <td>[poland]</td>\n",
       "      <td>[Poland]</td>\n",
       "      <td>[Poland]</td>\n",
       "      <td>[Poland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many Turing awards have people from Austri...</td>\n",
       "      <td>[Turing awards,  Austria]</td>\n",
       "      <td>[austria, many turing awards]</td>\n",
       "      <td>[Turing, Austria]</td>\n",
       "      <td>[Turing, Austria]</td>\n",
       "      <td>[Turing awards, Austria]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Give me all countries that have won a FIFA Wor...</td>\n",
       "      <td>[FIFA World Cup]</td>\n",
       "      <td>[fifa world cup]</td>\n",
       "      <td>[FIFA World Cup]</td>\n",
       "      <td>[FIFA World Cup]</td>\n",
       "      <td>[FIFA World Cup]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the population of Chile?</td>\n",
       "      <td>[Chile]</td>\n",
       "      <td>[chile]</td>\n",
       "      <td>[Chile]</td>\n",
       "      <td>[Chile]</td>\n",
       "      <td>[Chile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who is the author of One Piece?</td>\n",
       "      <td>[One Piece]</td>\n",
       "      <td>[one piece]</td>\n",
       "      <td>[One Piece]</td>\n",
       "      <td>[One Piece]</td>\n",
       "      <td>[One Piece]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Who wrote The Old Man and the Sea?</td>\n",
       "      <td>[The Old Man and the Sea]</td>\n",
       "      <td>[the old man and the sea]</td>\n",
       "      <td>[The Old Man and the Sea]</td>\n",
       "      <td>[The Old Man and the Sea]</td>\n",
       "      <td>[The Old Man and the Sea]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Which YouTube channels talk about maths?</td>\n",
       "      <td>[YouTube channels,  maths]</td>\n",
       "      <td>[youtube channels, maths]</td>\n",
       "      <td>[YouTube]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[YouTube]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>List Italian sauces.</td>\n",
       "      <td>[sauce,  Italy]</td>\n",
       "      <td>[italian sauces]</td>\n",
       "      <td>[Italian]</td>\n",
       "      <td>[Italian]</td>\n",
       "      <td>[Italian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>What diseases are associated with the gene FGF14?</td>\n",
       "      <td>[FGF14]</td>\n",
       "      <td>[gene fgf14]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[F]</td>\n",
       "      <td>[FGF14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>What ultra-cool dwarfs have been found in the ...</td>\n",
       "      <td>[ultra-cool dwarfs,  Aquarius]</td>\n",
       "      <td>[constellation aquarius]</td>\n",
       "      <td>[Aquarius]</td>\n",
       "      <td>[Aquarius]</td>\n",
       "      <td>[Aquarius]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0                     Who is the president of Poland?   \n",
       "1   How many Turing awards have people from Austri...   \n",
       "2   Give me all countries that have won a FIFA Wor...   \n",
       "3                    What is the population of Chile?   \n",
       "4                     Who is the author of One Piece?   \n",
       "..                                                ...   \n",
       "95                 Who wrote The Old Man and the Sea?   \n",
       "96           Which YouTube channels talk about maths?   \n",
       "97                               List Italian sauces.   \n",
       "98  What diseases are associated with the gene FGF14?   \n",
       "99  What ultra-cool dwarfs have been found in the ...   \n",
       "\n",
       "                          entities                MuHeQA_Keywords  \\\n",
       "0            [president of Poland]                       [poland]   \n",
       "1        [Turing awards,  Austria]  [austria, many turing awards]   \n",
       "2                 [FIFA World Cup]               [fifa world cup]   \n",
       "3                          [Chile]                        [chile]   \n",
       "4                      [One Piece]                    [one piece]   \n",
       "..                             ...                            ...   \n",
       "95       [The Old Man and the Sea]      [the old man and the sea]   \n",
       "96      [YouTube channels,  maths]      [youtube channels, maths]   \n",
       "97                 [sauce,  Italy]               [italian sauces]   \n",
       "98                         [FGF14]                   [gene fgf14]   \n",
       "99  [ultra-cool dwarfs,  Aquarius]       [constellation aquarius]   \n",
       "\n",
       "                    FLERT_NER                   BERT_NER  \\\n",
       "0                    [Poland]                   [Poland]   \n",
       "1           [Turing, Austria]          [Turing, Austria]   \n",
       "2            [FIFA World Cup]           [FIFA World Cup]   \n",
       "3                     [Chile]                    [Chile]   \n",
       "4                 [One Piece]                [One Piece]   \n",
       "..                        ...                        ...   \n",
       "95  [The Old Man and the Sea]  [The Old Man and the Sea]   \n",
       "96                  [YouTube]                         []   \n",
       "97                  [Italian]                  [Italian]   \n",
       "98                         []                        [F]   \n",
       "99                 [Aquarius]                 [Aquarius]   \n",
       "\n",
       "                  RoBERTA_NER  \n",
       "0                    [Poland]  \n",
       "1    [Turing awards, Austria]  \n",
       "2            [FIFA World Cup]  \n",
       "3                     [Chile]  \n",
       "4                 [One Piece]  \n",
       "..                        ...  \n",
       "95  [The Old Man and the Sea]  \n",
       "96                  [YouTube]  \n",
       "97                  [Italian]  \n",
       "98                    [FGF14]  \n",
       "99                 [Aquarius]  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_data('wqa_results',wqa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6d5a288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>empty</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>micro-precision</th>\n",
       "      <th>micro-recall</th>\n",
       "      <th>micro-f1</th>\n",
       "      <th>macro-precision</th>\n",
       "      <th>macro-recall</th>\n",
       "      <th>macro-f1</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>54</td>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.637584</td>\n",
       "      <td>0.671378</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.659167</td>\n",
       "      <td>0.667333</td>\n",
       "      <td>MuHeQA_Keywords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>93</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.375839</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.379167</td>\n",
       "      <td>0.407905</td>\n",
       "      <td>FLERT_NER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>98</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.342282</td>\n",
       "      <td>0.470046</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.372905</td>\n",
       "      <td>BERT_NER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.395973</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.399167</td>\n",
       "      <td>0.429571</td>\n",
       "      <td>RoBERTA_NER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total  empty  tp  tn  fp  fn  micro-precision  micro-recall  micro-f1  \\\n",
       "0     99      4  95   0  39  54         0.708955      0.637584  0.671378   \n",
       "1     99      4  56   0  11  93         0.835821      0.375839  0.518519   \n",
       "2     99      4  51   0  17  98         0.750000      0.342282  0.470046   \n",
       "3     99      4  59   0  10  90         0.855072      0.395973  0.541284   \n",
       "\n",
       "   macro-precision  macro-recall  macro-f1            model  \n",
       "0            0.725      0.659167  0.667333  MuHeQA_Keywords  \n",
       "1            0.470      0.379167  0.407905        FLERT_NER  \n",
       "2            0.430      0.344167  0.372905         BERT_NER  \n",
       "3            0.495      0.399167  0.429571      RoBERTA_NER  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_report('wqa_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881cef0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
